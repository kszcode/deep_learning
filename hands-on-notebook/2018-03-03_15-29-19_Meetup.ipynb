{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import keras as k\n",
    "\n",
    "from keras.datasets import mnist\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# chestii de keras de DL\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD, RMSprop, Adam\n",
    "from keras.models import Sequential\n",
    "from keras.utils import np_utils\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Magic numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped = 28*28\n",
    "nb_hidden_neurons_per_layer = 100\n",
    "nb_classes = 10\n",
    "# optim = SGD() # Stochastic Gradient Descent\n",
    "# optim = RMSprop() # Stochastic Gradient Descent\n",
    "optim = Adam() # Stochastic Gradient Descent\n",
    "nb_batch_size = 128\n",
    "nb_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('calea catre minist: ', '/usr/local/lib/python2.7/dist-packages/keras/datasets/mnist.pyc')\n"
     ]
    }
   ],
   "source": [
    "print(\"calea catre minist: \", mnist.__file__)\n",
    "#print(\"calea catre Dense: \", Dense.__file__)\n",
    "\n",
    "# ca sa avem aceleasi rezultate, ii dam un sid\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyse the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train.shape: ', (60000, 28, 28))\n",
      "('y_train.shape: ', (60000,))\n",
      "('x_test.shape', (10000, 28, 28))\n",
      "('y_test.shape', (10000,))\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"y_train.shape: \", y_train.shape)\n",
    "print(\"x_test.shape\", x_test.shape)\n",
    "print(\"y_test.shape\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('label: ', 9)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADmpJREFUeJzt3X+QVfV5x/HPw7qAoGZAC67IiD9WMo5tIdlAE5iOrYZR6wwkM9XQamlrs+kkNk3HaWtoppL2jzqdasY0PxisGHSsMY06MK2tP6gJY2MsC0EQiQEVRujCmqIVo8Au+/SPPaQr7vne6z3n3nPp837N7Oy95znnnoczfPbce7/3nq+5uwDEM67qBgBUg/ADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwjqlFbubLxN8Ima3MpdAqEc1s901I9YPesWCr+ZXSnpTkkdkv7B3W9LrT9RkzXfLi+ySwAJz/r6utdt+Gm/mXVI+rqkqyRdImmpmV3S6OMBaK0ir/nnSdrl7i+7+1FJ35a0uJy2ADRbkfDPkPTqqPt7s2XvYma9ZtZnZn2DOlJgdwDK1PR3+919lbv3uHtPpyY0e3cA6lQk/PskzRx1/9xsGYCTQJHwb5TUbWbnm9l4SZ+StK6ctgA0W8NDfe4+ZGY3SXpMI0N9q919e2mdAWiqQuP87v6opEdL6gVAC/HxXiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8ERfiBoAg/EBThB4IqNEuvme2WdEjSMUlD7t5TRlMAmq9Q+DO/5u4/LeFxALQQT/uBoIqG3yU9bmabzKy3jIYAtEbRp/0L3X2fmU2T9ISZ/djdN4xeIfuj0CtJEzWp4O4AlKXQmd/d92W/ByQ9ImneGOuscvced+/p1IQiuwNQoobDb2aTzez047clLZL0fFmNAWiuIk/7p0t6xMyOP84/uvu/ldIVgKZrOPzu/rKkXy6xFwAtxFAfEBThB4Ii/EBQhB8IivADQRF+IKgyvtWHGsZNSn+sedwHzkjWd3zxvGTdO/1993TcGV2HkvXn5j2QrL9+7O1k/fqF1+XWhva8mtwWzcWZHwiK8ANBEX4gKMIPBEX4gaAIPxAU4QeCYpy/BB3dFyTrB+5IH+Yffig9ll7E37/enazfs+bKZP0X/+OzyfqUnUPJ+ql7/jNZL6Jj9kXJ+q4Vk3NrnVvza5J07t/8oKGeTiac+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKMb569QxZUpubc53diW3/fK0HxXa95/un5+sP/2Nj+TWpj3z38ltz3mhuvHswSs+nKy/umh8sj73Yz9J1ref/2Bu7eLDTC3JmR8IivADQRF+ICjCDwRF+IGgCD8QFOEHgqo5zm9mqyVdI2nA3S/Nlk2V9KCkWZJ2S7rW3V9vXpvN13FG+tr5++45O7e2dtqTyW2femdisv6lv/6DZH3q/RuT9TOHnsmtHUtuWVytaxkcW3k0t/avH1yZ3HZcwXPT1qP5//rZXzuc3LbxmRBOHvUc3W9JOvGKD7dIWu/u3ZLWZ/cBnERqht/dN0g6eMLixZLWZLfXSFpScl8AmqzR51XT3b0/u71f0vSS+gHQIoXf8HN3V+Ilkpn1mlmfmfUN6kjR3QEoSaPhP2BmXZKU/R7IW9HdV7l7j7v3dGpCg7sDULZGw79O0rLs9jJJa8tpB0Cr1Ay/mT0g6RlJs81sr5ndKOk2SR83s52SrsjuAziJ1Bznd/elOaXLS+6lUn7Bucl630fua/ixv/zF30/Wp/xT/ji91Nwx51Nmpv/dx9ak99478/Fk/Tcm/U9ubf6m65PbHh1K//f80fx7k/Xf3PCHubXuTZuT20bAJ/yAoAg/EBThB4Ii/EBQhB8IivADQXHp7hY4NLMjWT+t4OMfvmZebm3vr6f/vt+zJP212o9OSH8peOUb6a/09nz9d3Jr56xMD7ed/b3OZL3W9OOzP/tibm04uWUMnPmBoAg/EBThB4Ii/EBQhB8IivADQRF+ICgbuQpXa5xhU32+tek3gcelx+J3/1X+WPrW3/tqcttBT4+VHxweStZr+UCi94mW/ijHd9/KvyS5JN33WydeuPndbMcryfrw22/n1iZ8P73vhy76l2T91oG5yfqmufHObc/6er3pB62edeMdHQCSCD8QFuEHgiL8QFCEHwiK8ANBEX4gKL7Pf9xweix+1pfyL6+9YM/nk9t+8o/+PVn/2OSdyXotn992XW7NnpqS3PbsO39Q49G3J6tFPiVy34WPJOuDnv7sxRNfXZCsT1X6kujRceYHgiL8QFCEHwiK8ANBEX4gKMIPBEX4gaBqjvOb2WpJ10gacPdLs2UrJH1a0mvZasvd/dFmNdnuzrwrPZ78/btOTdf1S4X236UdhbZvplNmnNPwto+/MzVZn3oP4/hF1HPm/5aksa7o8BV3n5P9hA0+cLKqGX533yDpYAt6AdBCRV7z32RmW81stZmlP0MKoO00Gv5vSrpQ0hxJ/ZJuz1vRzHrNrM/M+gZ1pMHdAShbQ+F39wPufszdhyXdJSn36pbuvsrde9y9p1MTGu0TQMkaCr+ZdY26+wlJz5fTDoBWqWeo7wFJl0k6y8z2SrpV0mVmNkcj3+jcLekzTewRQBPUDL+7Lx1j8d1N6AX/D71w64zc2iQbn9z2T7431n+9/3OxNjbUE0bwCT8gKMIPBEX4gaAIPxAU4QeCIvxAUFy6G4V0zL4oWf/nRanpy9NDfZNe6WygI9SLMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4PwrZd9W0ZP3izvyx/P5j7yS3nbX6pWR9KFlFLZz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvlRyKG5hxve9rJ1Nyfr3fufbfixURtnfiAowg8ERfiBoAg/EBThB4Ii/EBQhB8IquY4v5nNlHSvpOmSXNIqd7/TzKZKelDSLEm7JV3r7q83r1VU4Y0bPpqsv3jF1xp+7Nl/ti1ZH274kVGPes78Q5JudvdLJP2KpM+Z2SWSbpG03t27Ja3P7gM4SdQMv7v3u/vm7PYhSTskzZC0WNKabLU1kpY0q0kA5Xtfr/nNbJakuZKelTTd3fuz0n6NvCwAcJKoO/xmdpqkhyR9wd3fHF1zd9fI+wFjbddrZn1m1jeoI4WaBVCeusJvZp0aCf797v5wtviAmXVl9S5JA2Nt6+6r3L3H3Xs6NaGMngGUoGb4zcwk3S1ph7vfMaq0TtKy7PYySWvLbw9As9Tzld4Fkm6QtM3MtmTLlku6TdJ3zOxGSXskXducFlGl1y4/Wmj7335lUW5t+PAbhR4bxdQMv7s/LclyypeX2w6AVuETfkBQhB8IivADQRF+ICjCDwRF+IGguHR3cB1TpiTry+Y+U+jx+2+/KLc2aZhLc1eJMz8QFOEHgiL8QFCEHwiK8ANBEX4gKMIPBMU4f3A/W9CdrC8/68lk/bqXrkzWT3ss//LcXJq7Wpz5gaAIPxAU4QeCIvxAUIQfCIrwA0ERfiAoxvlRyI4DZyfr581OjOY/9+P0gw8fa6Aj1IszPxAU4QeCIvxAUIQfCIrwA0ERfiAowg8EVXOc38xmSrpX0nRJLmmVu99pZiskfVrSa9mqy9390WY1iva0dt7KZP2Nh8fn1v7ygwuT2/oRxvmbqZ4P+QxJutndN5vZ6ZI2mdkTWe0r7v53zWsPQLPUDL+790vqz24fMrMdkmY0uzEAzfW+XvOb2SxJcyUdn2fpJjPbamarzWzMeZ/MrNfM+sysb1BHCjULoDx1h9/MTpP0kKQvuPubkr4p6UJJczTyzOD2sbZz91Xu3uPuPZ2aUELLAMpQV/jNrFMjwb/f3R+WJHc/4O7H3H1Y0l2S5jWvTQBlqxl+MzNJd0va4e53jFreNWq1T0h6vvz2ADRLPe/2L5B0g6RtZrYlW7Zc0lIzm6OR4b/dkj7TlA7RVKc+tiVZ//DG65P1Q/91erJ+5uaO/NrRHya3RXPV827/05JsjBJj+sBJjE/4AUERfiAowg8ERfiBoAg/EBThB4Li0t3B+eDRZL1ryY50vcxm0FKc+YGgCD8QFOEHgiL8QFCEHwiK8ANBEX4gKHP31u3M7DVJe0YtOkvST1vWwPvTrr21a18SvTWqzN7Oc/dfqGfFlob/PTs363P3nsoaSGjX3tq1L4neGlVVbzztB4Ii/EBQVYd/VcX7T2nX3tq1L4neGlVJb5W+5gdQnarP/AAqUkn4zexKM3vRzHaZ2S1V9JDHzHab2TYz22JmfRX3strMBszs+VHLpprZE2a2M/s95jRpFfW2wsz2Zcdui5ldXVFvM83sKTN7wcy2m9kfZ8srPXaJvio5bi1/2m9mHZJ+IunjkvZK2ihpqbu/0NJGcpjZbkk97l75mLCZ/aqktyTd6+6XZsv+VtJBd78t+8M5xd3/vE16WyHprapnbs4mlOkaPbO0pCWSflcVHrtEX9eqguNWxZl/nqRd7v6yux+V9G1Jiyvoo+25+wZJB09YvFjSmuz2Go3852m5nN7agrv3u/vm7PYhScdnlq702CX6qkQV4Z8h6dVR9/eqvab8dkmPm9kmM+utupkxTM+mTZek/ZKmV9nMGGrO3NxKJ8ws3TbHrpEZr8vGG37vtdDdPyTpKkmfy57etiUfec3WTsM1dc3c3CpjzCz9c1Ueu0ZnvC5bFeHfJ2nmqPvnZsvagrvvy34PSHpE7Tf78IHjk6Rmvwcq7ufn2mnm5rFmllYbHLt2mvG6ivBvlNRtZueb2XhJn5K0roI+3sPMJmdvxMjMJktapPabfXidpGXZ7WWS1lbYy7u0y8zNeTNLq+Jj13YzXrt7y38kXa2Rd/xfkvQXVfSQ09cFkp7LfrZX3ZukBzTyNHBQI++N3CjpTEnrJe2U9KSkqW3U232StknaqpGgdVXU20KNPKXfKmlL9nN11ccu0Vclx41P+AFB8YYfEBThB4Ii/EBQhB8IivADQRF+ICjCDwRF+IGg/hcqIE04MAdZzAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d925bcc50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "index = 154\n",
    "plt.imshow(x_train[index])\n",
    "print(\"label: \", y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('min pixelilor: ', 0)\n",
      "('max pixelilor: ', 255)\n"
     ]
    }
   ],
   "source": [
    "print(\"min pixelilor: \", np.min(x_train))\n",
    "print(\"max pixelilor: \", np.max(x_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unroll the vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_train.shape: ', (60000, 784))\n",
      "('x_test.shape', (10000, 784))\n",
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = np.reshape(x_train, (x_train.shape[0], reshaped))\n",
    "x_test = np.reshape(x_test, (x_test.shape[0], reshaped))\n",
    "print(\"x_train.shape: \", x_train.shape)\n",
    "print(\"x_test.shape\", x_test.shape)\n",
    "# print(\"x_test.shape\", len(x_test[1]))\n",
    "print(type(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensure Float and Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<type 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "print(type(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One-hot enoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('label: ', 3)\n"
     ]
    }
   ],
   "source": [
    "index = 12\n",
    "# plt.imshow(x_train[index])\n",
    "print(\"label: \", y_train[index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "y_test = np_utils.to_categorical(y_test, nb_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('label: ', array([0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]))\n",
      "('type(y_train): ', <type 'numpy.ndarray'>)\n",
      "('min pixelilor: ', 0.0)\n",
      "('max pixelilor: ', 1.0)\n"
     ]
    }
   ],
   "source": [
    "print(\"label: \", y_train[index])\n",
    "print(\"type(y_train): \", type(y_train))\n",
    "print(\"min pixelilor: \", np.min(x_train))\n",
    "print(\"max pixelilor: \", np.max(x_train))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 89,610\n",
      "Trainable params: 89,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(nb_hidden_neurons_per_layer, input_shape=(reshaped,)))\n",
    "model.add(Dense(nb_hidden_neurons_per_layer))\n",
    "model.add(Dense(nb_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "# get some info\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', \n",
    "              optimizer=optim, \n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/20\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.4093 - acc: 0.8814 - val_loss: 0.2914 - val_acc: 0.9197\n",
      "Epoch 2/20\n",
      "48000/48000 [==============================] - 2s 46us/step - loss: 0.3031 - acc: 0.9137 - val_loss: 0.2814 - val_acc: 0.9233\n",
      "Epoch 3/20\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.2888 - acc: 0.9192 - val_loss: 0.2949 - val_acc: 0.9167\n",
      "Epoch 4/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2848 - acc: 0.9203 - val_loss: 0.2757 - val_acc: 0.9251\n",
      "Epoch 5/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2783 - acc: 0.9210 - val_loss: 0.2828 - val_acc: 0.9226\n",
      "Epoch 6/20\n",
      "48000/48000 [==============================] - 2s 35us/step - loss: 0.2734 - acc: 0.9230 - val_loss: 0.2803 - val_acc: 0.9218\n",
      "Epoch 7/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2713 - acc: 0.9242 - val_loss: 0.2774 - val_acc: 0.9257\n",
      "Epoch 8/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2690 - acc: 0.9249 - val_loss: 0.2783 - val_acc: 0.9248\n",
      "Epoch 9/20\n",
      "48000/48000 [==============================] - 2s 36us/step - loss: 0.2671 - acc: 0.9249 - val_loss: 0.2796 - val_acc: 0.9246\n",
      "Epoch 10/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2638 - acc: 0.9255 - val_loss: 0.2757 - val_acc: 0.9235\n",
      "Epoch 11/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2606 - acc: 0.9267 - val_loss: 0.2843 - val_acc: 0.9237\n",
      "Epoch 12/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2628 - acc: 0.9259 - val_loss: 0.2846 - val_acc: 0.9230\n",
      "Epoch 13/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.2568 - acc: 0.9283 - val_loss: 0.2712 - val_acc: 0.9258\n",
      "Epoch 14/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.2594 - acc: 0.9264 - val_loss: 0.2841 - val_acc: 0.9251\n",
      "Epoch 15/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.2579 - acc: 0.9281 - val_loss: 0.2874 - val_acc: 0.9227\n",
      "Epoch 16/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2542 - acc: 0.9283 - val_loss: 0.2982 - val_acc: 0.9166\n",
      "Epoch 17/20\n",
      "48000/48000 [==============================] - 2s 42us/step - loss: 0.2539 - acc: 0.9282 - val_loss: 0.2874 - val_acc: 0.9217\n",
      "Epoch 18/20\n",
      "48000/48000 [==============================] - 2s 40us/step - loss: 0.2540 - acc: 0.9280 - val_loss: 0.2738 - val_acc: 0.9287\n",
      "Epoch 19/20\n",
      "48000/48000 [==============================] - 2s 38us/step - loss: 0.2539 - acc: 0.9289 - val_loss: 0.2820 - val_acc: 0.9230\n",
      "Epoch 20/20\n",
      "48000/48000 [==============================] - 2s 37us/step - loss: 0.2531 - acc: 0.9290 - val_loss: 0.2781 - val_acc: 0.9268\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x_train, \n",
    "                    y_train, \n",
    "                    batch_size=nb_batch_size, \n",
    "                    epochs=nb_epochs, \n",
    "                    verbose=1, \n",
    "                    validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 17us/step\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(x_test, y_test, batch_size=nb_batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('score: ', 0.2945993344187737)\n",
      "('accuracy: ', 0.9222)\n"
     ]
    }
   ],
   "source": [
    "print(\"score: \", score[0])\n",
    "print(\"accuracy: \", score[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find examples where the algorithm failed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_test => realitatea\n",
    "# y_predicted => , trebuie compara\n",
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9201224e-07, 3.2869127e-14, 2.1480062e-07, 3.9632872e-04,\n",
       "       3.7358340e-08, 1.7995914e-06, 7.4410188e-13, 9.9952626e-01,\n",
       "       1.0031846e-06, 7.4183190e-05], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = np.max(y_pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99952626"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.9201224e-07, 3.2869127e-14, 2.1480062e-07, 3.9632872e-04,\n",
       "       3.7358340e-08, 1.7995914e-06, 7.4410188e-13, 9.9952626e-01,\n",
       "       1.0031846e-06, 7.4183190e-05], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('x_test_prim.shape: ', (784,))\n",
      "('Real label: ', array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f7d39eba710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot\n",
    "x_test_prim = x_test[0]\n",
    "print(\"x_test_prim.shape: \", x_test_prim.shape)\n",
    "x_test_prim = np.reshape(x_test_prim, (28,28))\n",
    "plt.imshow(x_test_prim)\n",
    "print(\"Real label: \", y_test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking : expected dense_1_input to have shape (784,) but got array with shape (28,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-01bcb6434258>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpred_prim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_prim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict_classes\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1136\u001b[0m         \"\"\"\n\u001b[1;32m   1137\u001b[0m         proba = self.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1138\u001b[0;31m                              steps=steps)\n\u001b[0m\u001b[1;32m   1139\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mproba\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/models.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1023\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1024\u001b[0m         return self.model.predict(x, batch_size=batch_size, verbose=verbose,\n\u001b[0;32m-> 1025\u001b[0;31m                                   steps=steps)\n\u001b[0m\u001b[1;32m   1026\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1027\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps)\u001b[0m\n\u001b[1;32m   1822\u001b[0m         x = _standardize_input_data(x, self._feed_input_names,\n\u001b[1;32m   1823\u001b[0m                                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_feed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1824\u001b[0;31m                                     check_batch_axis=False)\n\u001b[0m\u001b[1;32m   1825\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstateful\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1826\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    121\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    124\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking : expected dense_1_input to have shape (784,) but got array with shape (28,)"
     ]
    }
   ],
   "source": [
    "pred_prim = model.predict_classes(x_test_prim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
